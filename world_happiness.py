# -*- coding: utf-8 -*-
"""world happiness.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PoIG3DoP7U2lHKgQZK_R_LmocEi3dNXb
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df=pd.read_csv('/content/world happineness execl.csv')
df

df.head()

"""first 5 rows of data"""

df.tail()

"""last 5 rows of data"""

df.columns

"""columns which present in data"""

df.describe()

"""by using describe method we can learn some statistical ingormation about data"""

df.shape

"""there are 158 rows and 12 columns """

df.isnull().sum()

"""there is no null values """

df.info()

"""total information about int , object , float

#EDA
"""

df1=df.Region.value_counts()
plt.figure(figsize=(10,10))
sns.barplot(x=df1.index,y=df1.values)
plt.xlabel('Region')
plt.xticks(rotation=90)
plt.ylabel('No.of country')
plt.show()

"""region v/s no of country"""

corr_hmap=df.corr()
plt.figure(figsize=(15,15))
sns.heatmap(corr_hmap,annot=True)
plt.show()

from sklearn.preprocessing import LabelEncoder
labelencoder=LabelEncoder()
for column in df.columns:
  df[column]=labelencoder.fit_transform(df[column])

"""label encoding the data"""

df.head()

df.head()

sns.countplot(df['Region'])

"""comparing region v/s count using count plot"""

sns.boxplot(df['Region'])

"""there is no outler """

plt.figure(figsize=[10,6])
plt.title('comparision between Happiness Rank and Economy (GDP per Capita)' )
sns.scatterplot(df['Economy (GDP per Capita)'],df['Happiness Rank'],hue=df['Region']);

"""camparing gdp vs happiness as gdp increases happyness  as increases"""

df.rename({'Happiness Score': 'Happiness_Score'},axis=1,inplace=True)
df

x=df.drop('Happiness_Score',axis=1)
y=df.Happiness_Score

from sklearn.model_selection import train_test_split,cross_val_score
x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=20)
print(x_train.shape,x_test.shape)
print(y_train.shape,y_test.shape)

from sklearn.metrics import mean_absolute_error
from sklearn.metrics import mean_squared_error
from sklearn.metrics import r2_score
from sklearn.model_selection import train_test_split
def maxr2_score(regr,x,y):
    max_r_score=0
    for r_state in range(40,101):
        x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=r_state,test_size=0.30)
        regr.fit(x_train,y_train)
        y_pred=regr.predict(x_test)
        r2_scr=r2_score(y_test,y_pred)
        print("r2 score corrospoding to ",r_state,"is",r2_scr)
        if r2_scr>max_r_score:
            max_r_score=r2_scr
            final_r_state=r_state
    print("max r2 score to ",final_r_state,"is",max_r_score)
    return final_r_state

from sklearn.linear_model import LinearRegression
lreg=LinearRegression()
r_state=maxr2_score(lreg,x,y)

"""maxmium r2 score to 40 is 1.0"""

from sklearn.model_selection import cross_val_score
from sklearn.linear_model import LinearRegression
cross_val_score(LinearRegression(),x,y,cv=5,scoring='neg_mean_absolute_error').mean()

x_train,x_test,y_train,y_test=train_test_split(x,y,random_state =62,test_size=0.33)
lreg=LinearRegression()
lreg.fit(x_train,y_train)
y_pred=lreg.predict(x_test)

from sklearn.metrics import r2_score
from sklearn.metrics import mean_squared_error
print("r2 score is :",r2_score(y_test,y_pred))
print('RMSE is :',np.sqrt(mean_squared_error(y_test,y_pred)))

import pickle

project2_model = pickle.dumps(lreg) 
lreg_from_pickle = pickle.loads(project2_model) 
lreg_from_pickle.predict(x_test)

